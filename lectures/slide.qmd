---
title: "Large Language Models and Applications"
author: "Calvin Williamson, Science and Math"
date: Sept 2025
format: 
  revealjs:
    mermaid:
      theme: forest
---

## Large Language Models (LLM)

- AI Models You Send a Prompt and They Give a Response 
- ChatGPT, Claude, Gemini, DeepSeek, Many Others 
- Prompts can include Text, Images, Audio, Video
- Responses can include Text, Images, Audio, Video 

## Text Based LLMs 

To prompt an LLM with text you type your question and submit it 

```{mermaid}
sequenceDiagram
    participant User
    participant LLM
    User->>LLM: Prompt: What is the capital of France?
    LLM->>User: Response: The capital of France is Paris.
```
The model responds with some text.

**Example**: ChatGPT 3.5 (Nov 22) 

## MultiModal LLMs

Prompts can include 

- Text
- Image (eg. uploaded image file) 
- Audio (eg. from microphone, or uploaded audio file) 
- Video (eg Webcam) 
- Screen sharing (eg show your computer screen)

Responses can include: Text, Image, Audio, Video   

**Example**: Gemini 2.0 Flash (Dec 24) 

## How To Prompt a MultiModal LLM using Audio 

To prompt the LLM you speak into a microphone on your computer 

```{mermaid}
sequenceDiagram
    participant User
    participant LLM
    User->>LLM: Audio Prompt ðŸ”Š: Can you hear me? 
    LLM->>User: Audio Response ðŸ”Š: Yes! I hear you? How can I help you today?
```

The model responds in audio and/or text that you can hear and see immediately


## How To Prompt a MultiModal LLM using Video and Audio

Using a webcam you speak and show the model what you want 

```{mermaid}
sequenceDiagram
    participant User
    participant LLM
    User->>LLM: Webcam Prompt ðŸ“¹+ðŸ”Š: Can you see and hear me? 
    LLM->>User: Audio Response ðŸ”Š: Yes! I can both see and hear you. How can I help you today?
    
```
The model responds in audio and/or text

## Large Language Models as Software Developers 

- Language models are excellent at writing software. 
- The term *Vibe Coding* has been used to describe the act of coding and not looking at the source code but just prompting the model to write things. 
  - GPT 5 (OpenAI)
  - Claude Sonnet and Opus (Anthropic)
  - Gemini 2.5 Pro (Google) 
  - Qwen3-Coder

## Large Language Models as Artists? 

Claude Sonnet And Qwen3-Coder Compositions in a Musical Software Language:

- [Claude 1](https://shorturl.at/nGg2s)
- [Claude 2](https://shorturl.at/1TP2e)
- [Qwen3-Coder Draft](https://shorturl.at/7deQN)
- [Qwen3-Coder Finished](https://shorturl.at/DjtMz)


## Large Language Model: Deep Seek {.smaller}

In Spring 25 a new model called Deep Seek caused Wall Street to panic and lose Billions of dollars. The reason is the Deep Seek was released as an open source model that anyone could download and run on their own, thus challenging the idea that only companies with proprietary models would dominate the AI space. The models from OpenAI, Anthropic, Google all are proprietary models:

- ChatGPT (OpenAI)
- Claude (Anthropic)
- Gemini (Google) 

These models cannot be run by anyone the way Deep Seek can. 

## Examples of Reasoning Models: Deep Seek {.smaller}

1. [Barbie Deep Think](BarbieDeepThink.html)
2. [Making a Todo App with DeepSeek](DeepSeekSession.html) | [Version 1](DeepSeek1.html) | [Version 2](DeepSeek2.html)

Deep Seeks models are competive with the state of the art closed source models but are created at a fraction of the cost.
 
Notice the difference when posting prompts to the standard V3 models versus the "reasoning model" (Button "DeepThink"). The reasoning model shows you its thinking process.

## Large Language Model: Qwen {.smaller}

- Navigate to [Qwen](https://chat.qwen.ai) and create an account to use the Qwen models. 
- Qwen has both coding models (Qwen3-Coder) and regular models. Also they have Reasoning models.  
- Qwen has recently released state of the art Image Editing and Image Generation Features 

## Qwen3-Coder Assignment #1 Coding {.smaller}

Using the techniques demonstrated in the demo, have Qwen3-Coder create an html, javascript and css application for you to play tick tac toe. 

- Ask the model to create the application all in one index.html file so that you can preview it.
- Make sure the model creates an "artifact" window that allows you to preview the html application
- Have the model create a scoring system for multiple games so you can keep score of the number of times X's win and the number of times Y's win
- Ask the model to implement a "hint" feature so that it shows a suggested move for the next player

Test out the Thinking feature if you can. This is where models "think" longer. 

## Qwen Assignment #2 Image Editing and Generation {.smaller}

1. Upload an image with some objects and ask Qwen to remove some of the objects. 
2. Try it with some people (Something from Google Images of someone famous is 
   fine) 
3. Ask Qwen to generate an image 
4. Ask Qwen to generate a carton
5. Upload an image of a person (Something from Google Images is okay) and ask it to make part of the picture into a cartoon (just a part). 
6. Using an image of a person get Qwen to show you the person from a different viewpoint    

## Example LLM Application: NotebookLM {.smaller}

* Navigate to [NotebookLM](https://notebooklm.google.com) and create an account using your private (non-FIT) email.

Pdfs to upload   

- [Interaction of Light and Matter](InteractionLightMatter.pdf)
- [Lights and White](LightsAndWhite.pdf)
- [Scientfic Notation](ScientificNotationPropertiesOfWaves.pdf)

NotebookLM is an AI-powered note-taking and knowledge management
tool designed to help users organize, summarize, and interact with
their notes and documents more effectively. It leverages natural
language processing to provide insights, generate summaries, and
answer questions based on the content you input, making it easier
to manage and extract value from large amounts of information.

## NotebookLM Assignment {.smaller}

## Example Multimodal LLM: Gemini 2.5 Flash {.smaller}

* Navigate to [Google AI Studio](https://aistudio.google.com) and login with an private gmail account to use the gemini 2 models. (Again use a private gmail account since FIT gmail accounts do not have access at this time) 
* Make sure the model selected is "Gemini 2.0 Flash Experimental"
* Click on the Stream Realtime button 
  * Click on Talk to Gemini and try talking to the LLM
  * Click on Show Gemini and use your webcam to show it something in the room
  * Click on Share your Screen and show it something on your compputer.

[Geminin 2 Flash MultiModal Live API](https://youtube.com/playlist?list=PL3miIiuTRI6cEN04Yx_W0u0OLuhV_bFx7&si=ASUC7DgmNYh9zXoM)  
[Gemini 2.0 - How to use the Live Bidirectional API](https://youtu.be/CZ9WaMbiTO4?si=0QgJhAWbeLVGq5ec)   
[Best Ways to use Gemini 2.0](https://www.youtube.com/watch?v=kN93lrS1nfw&t=226s)  
